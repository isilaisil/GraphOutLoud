{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# required libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters and URLs\n",
    "path = str(Path(os.path.abspath(os.getcwd())).parent.absolute())\n",
    "youtubeUrl = path + '/DB2/top_200_youtubers.csv'\n",
    "instaUrl = path + '/DB2/Top_50_Most_Followed_Instagram_Accounts.csv'\n",
    "twitterUrl = path + '/DB2/Top_1000_Celebrity_Twitter_Accounts.csv'\n",
    "grammyUrl = path + '/DB2/Grammy_Award.csv'\n",
    "\n",
    "# country codes\n",
    "countriesURL = path + '/DB2/wikipedia-iso-country-codes.csv'\n",
    "\n",
    "# saving folder\n",
    "savePath =  path + '/DB2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV files in memory\n",
    "instagram = pd.read_csv(instaUrl, sep=',', index_col='instaid',encoding='cp1252')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the country codes\n",
    "countries = pd.read_csv(countriesURL, sep=',', index_col='Name', keep_default_na=False, na_values=['_'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 50 entries, ID1550 to ID1571\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Rank        50 non-null     int64  \n",
      " 1   Username    50 non-null     object \n",
      " 2   Owner       50 non-null     object \n",
      " 3   Followers   50 non-null     float64\n",
      " 4   Profession  50 non-null     object \n",
      " 5   Country     50 non-null     object \n",
      "dtypes: float64(1), int64(1), object(4)\n",
      "memory usage: 2.7+ KB\n"
     ]
    }
   ],
   "source": [
    "instagram.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the required libraries\n",
    "from rdflib import Graph, Literal, RDF, URIRef, Namespace\n",
    "# rdflib knows about some namespaces, like FOAF\n",
    "from rdflib.namespace import FOAF, XSD\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the country and the movie ontology namespaces not known by RDFlib\n",
    "CNS = Namespace(\"http://eulersharp.sourceforge.net/2003/03swap/countries#\")\n",
    "IN = Namespace(\"Instagram#\")\n",
    "\n",
    "#create the graph\n",
    "g = Graph()\n",
    "\n",
    "# Bind the namespaces to a prefix for more readable output\n",
    "g.bind(\"countries\", CNS)\n",
    "g.bind(\"in\", IN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check date\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 31.2 ms\n",
      "Wall time: 56.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "#measure execution time\n",
    "\n",
    "#iterate over the instagram dataframe\n",
    "for index, row in instagram.iterrows():\n",
    "\n",
    "    Insta = URIRef(IN[index])\n",
    "\n",
    "    g.add((Insta, RDF.type, IN.Insta))\n",
    "    g.add((Insta, IN['rank'], Literal(row['Rank'], datatype=XSD.integer)))\n",
    "    g.add((Insta, IN['username'], Literal(row['Username'], datatype=XSD.string)))\n",
    "    g.add((Insta, IN['owner'], Literal(row['Owner'], datatype=XSD.string)))\n",
    "    g.add((Insta, IN['folllowers'], Literal(row['Followers'], datatype=XSD.integer)))\n",
    "\n",
    "   \n",
    "    for pf in row['Profession'].split(','):\n",
    "        prof = URIRef(IN[pf.strip()])\n",
    "        g.add((Insta,IN['hasprofession'], prof))    \n",
    "        \n",
    "    for c in str(row['Country']).split(','):\n",
    "        cName = c.strip()\n",
    "        # check if the country exists\n",
    "        # country.index == x returns an array of booleans, thus we need to use the any() method\n",
    "        if((countries.index == cName).any() == True):\n",
    "            #get the country code, convert to string and get the lower case to match the country codes in the ontology \n",
    "            code = str(countries[countries.index == cName]['Alpha-2 code'][0]).lower()\n",
    "            # create the RDF node\n",
    "            Country = URIRef(CNS[code])\n",
    "            # add the edge connecting the Movie and the Country \n",
    "            g.add((Insta, IN['hasCountry'], Country))  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- saving serialization ---\n",
      "CPU times: total: 31.2 ms\n",
      "Wall time: 51.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# print all the data in the Turtle format\n",
    "print(\"--- saving serialization ---\")\n",
    "with open(savePath + 'instagram.ttl', 'w') as file:\n",
    "    file.write(g.serialize(format='turtle'))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Youtube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "youtube = pd.read_csv(youtubeUrl, sep=',', index_col='youtubeid', keep_default_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 593 entries, ID921 to ID1512\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Country       593 non-null    object \n",
      " 1   Channel_Name  593 non-null    object \n",
      " 2   Category      593 non-null    object \n",
      " 3   username      593 non-null    object \n",
      " 4   followers     593 non-null    int64  \n",
      " 5   Likes         593 non-null    float64\n",
      " 6   Views         593 non-null    float64\n",
      " 7   Views_Avg     593 non-null    float64\n",
      " 8   Comments_Avg  593 non-null    float64\n",
      "dtypes: float64(4), int64(1), object(4)\n",
      "memory usage: 46.3+ KB\n"
     ]
    }
   ],
   "source": [
    "youtube.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNS = Namespace(\"http://eulersharp.sourceforge.net/2003/03swap/countries#\")\n",
    "YT = Namespace(\"Youtube#\")\n",
    "\n",
    "g.bind(\"countries\", CNS)\n",
    "g.bind(\"yt\", YT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "People are modeled with the FOAF ontology. \n",
    "Refer to [FOAF Documentation](http://xmlns.com/foaf/spec/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.11 s\n",
      "Wall time: 1.24 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "for index, row in youtube.iterrows():\n",
    "\n",
    "    YouTube = URIRef(YT[index])\n",
    "    \n",
    "    g.add((YouTube, RDF.type, YT.YouTube))\n",
    "    g.add((YouTube, YT['channelname'], Literal(row['Channel_Name'], datatype=XSD.string)))\n",
    "    g.add((YouTube, YT['category'], Literal(row['Category'], datatype=XSD.string)))\n",
    "    g.add((YouTube, YT['username'], Literal(row['username'], datatype=XSD.string)))\n",
    "    g.add((YouTube, YT['followers'], Literal(row['followers'], datatype=XSD.integer)))\n",
    "    g.add((YouTube, YT['likes'], Literal(row['Likes'], datatype=XSD.float)))\n",
    "    g.add((YouTube, YT['views'], Literal(row['Views'], datatype=XSD.float)))\n",
    "    g.add((YouTube, YT['viewsavg'], Literal(row['Views_Avg'], datatype=XSD.float)))\n",
    "    g.add((YouTube, YT['commentsavg'], Literal(row['Comments_Avg'], datatype=XSD.float)))\n",
    "    \n",
    "    i=0\n",
    "    for c in str(row['Country']).split(',') :\n",
    "        cName = c.strip()\n",
    "        for i in range(0,len(youtube)):\n",
    "            if ( cName  == countries['Alpha-2 code'][i]):\n",
    "                code = str(countries['Alpha-2 code'][i]).lower()\n",
    "                cty = URIRef(CNS[code])\n",
    "                g.add((YouTube, YT['hasCountry'], cty)) \n",
    "                break\n",
    "    \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- saving serialization ---\n",
      "CPU times: total: 62.5 ms\n",
      "Wall time: 116 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# print all the data in the Turtle format\n",
    "print(\"--- saving serialization ---\")\n",
    "with open(savePath + 'youtube.ttl', 'w') as file:\n",
    "    file.write(g.serialize(format='turtle'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV files in memory\n",
    "twitter = pd.read_csv(twitterUrl, sep=',', index_col='twitterid', keep_default_na=False, na_values=['_'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 920 entries, ID0001 to ID0920\n",
      "Data columns (total 6 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   twitter_username  920 non-null    object\n",
      " 1   twitter_userid    920 non-null    object\n",
      " 2   domain            920 non-null    object\n",
      " 3   name              920 non-null    object\n",
      " 4   followers_count   920 non-null    object\n",
      " 5   tweet_count       920 non-null    object\n",
      "dtypes: object(6)\n",
      "memory usage: 50.3+ KB\n"
     ]
    }
   ],
   "source": [
    "twitter.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new graph\n",
    "g = Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regular expressions\n",
    "TW = Namespace(\"Twitter#\")\n",
    "g.bind(\"tw\", TW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 516 ms\n",
      "Wall time: 510 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "#measure execution time\n",
    "\n",
    "#iterate over the person dataframe\n",
    "for index, row in twitter.iterrows():\n",
    "    # Create the node to add to the Graph\n",
    "    # the node has the namespace + the person id as URI\n",
    "    Tweet = URIRef(TW[index])\n",
    "    g.add((Tweet, RDF.type, TW.Twitter))\n",
    "    g.add((Tweet, TW['username'], Literal(row['twitter_username'], datatype=XSD.string)))\n",
    "    g.add((Tweet, TW['userid'], Literal(row['twitter_userid'], datatype=XSD.string)))\n",
    "    g.add((Tweet, TW['domain'], Literal(row['domain'], datatype=XSD.string)))\n",
    "    g.add((Tweet, TW['name'], Literal(row['name'], datatype=XSD.string)))\n",
    "    g.add((Tweet, TW['followers'], Literal(row['followers_count'], datatype=XSD.string)))\n",
    "    g.add((Tweet, TW['tweetscount'], Literal(row['tweet_count'], datatype=XSD.string)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- saving serialization ---\n",
      "CPU times: total: 297 ms\n",
      "Wall time: 326 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# print all the data in the Turtle format\n",
    "print(\"--- saving serialization ---\")\n",
    "with open(savePath + 'twitter.ttl', 'w', encoding=\"utf-8\") as file:\n",
    "    file.write(g.serialize(format='turtle'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grammy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Song_Name    object\n",
       "Artist       object\n",
       "Year          int32\n",
       "Winner         bool\n",
       "dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grammy = pd.read_csv(grammyUrl, sep=',', index_col='songid', encoding='cp1252')\n",
    "grammy.astype({'Year': 'int32'}).dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 110 entries, ID0001 to ID0110\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   Song_Name  110 non-null    object\n",
      " 1   Artist     110 non-null    object\n",
      " 2   Year       110 non-null    int64 \n",
      " 3   Winner     110 non-null    bool  \n",
      "dtypes: bool(1), int64(1), object(2)\n",
      "memory usage: 3.5+ KB\n"
     ]
    }
   ],
   "source": [
    "grammy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "GM = Namespace(\"Grammy#\")\n",
    "g.bind(\"gm\", GM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:17\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not callable"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "#measure execution time\n",
    "\n",
    "#iterate over the person dataframe\n",
    "for index, row in grammy.iterrows():\n",
    "    # Create the node to add to the Graph\n",
    "    # the node has the namespace + the person id as URI\n",
    "    Award = URIRef(GM[index])\n",
    "    g.add((Award, RDF.type, GM.Grammy))\n",
    "    g.add((Award, GM['songname'], Literal(row['Song_Name'], datatype=XSD.string)))\n",
    "    g.add((Award, GM['artists'], Literal(row['Artist'], datatype=XSD.string)))\n",
    "    g.add((Award, GM['year'], Literal(row['Year'], datatype=XSD.string)))\n",
    "    g.add((Award, GM['winner'], Literal(row['Winner'], datatype=XSD.gYear)))\n",
    "    \n",
    "    pp = ''\n",
    "    for p in row['Artist'].split(' '):\n",
    "        pp = pp+p\n",
    "    print(len(pp))\n",
    "    for pf in pp.split(','):\n",
    "        Art = URIRef(GM[pf.strip()])\n",
    "        g.add((Award,GM['hasartists'], Art))   \n",
    "        \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- saving serialization ---\n",
      "CPU times: total: 15.6 ms\n",
      "Wall time: 2.08 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# print all the data in the Turtle format\n",
    "print(\"--- saving serialization ---\")\n",
    "with open(savePath + 'grammy.ttl', 'w', encoding=\"utf-8\") as file:\n",
    "    file.write(g.serialize(format='turtle'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Singers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length =  72\n"
     ]
    }
   ],
   "source": [
    "g = Graph()\n",
    "\n",
    "SN = Namespace(\"Singers#\")\n",
    "g.bind(\"countries\", CNS)\n",
    "g.bind(\"sn\", SN)\n",
    "singerlist = []\n",
    "\n",
    "\n",
    "\n",
    "for index, row in instagram.iterrows():\n",
    "    namelt = []\n",
    "    for name in row['Profession'].split(','):\n",
    "        namelt.append(name)\n",
    "\n",
    "    if len(namelt)>1:\n",
    "        for i in range(0,len(namelist)):\n",
    "            if namelt[i] == 'Musician':\n",
    "                name = ''\n",
    "                for n in row['Owner'].split(' '):\n",
    "                    name = name +n\n",
    "                singerlist.append(name)\n",
    "    elif namelt[0] == 'Musician':\n",
    "        name = ''\n",
    "        for n in row['Owner'].split(' '):\n",
    "            name = name +n\n",
    "        singerlist.append(name)\n",
    "\n",
    "\n",
    "\n",
    "for index,row in youtube.iterrows():\n",
    "    namelist = []\n",
    "    for name in row['Category'].split(','):\n",
    "        namelist.append(name)\n",
    "    for i in range(0,len(namelist)): \n",
    "        if namelist[i] == 'Music' or namelist[i]== 'Pop music'  or namelist[i]=='Hip hop music' or \\\n",
    "        namelist[i]== 'Rock music' or namelist[i]== 'Music of Asia' or namelist[i]== 'Music of Latin America'\\\n",
    "        or namelist[i]== 'Electronic music' or namelist[i]== 'Rhythm and blues':\n",
    "            name = ''\n",
    "            for n in row['username'].split(' '):\n",
    "                name = name + n\n",
    "            if name not in singerlist:\n",
    "                singerlist.append(name)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "# print(singerlist)\n",
    "# print('length = ',len(singerlist))\n",
    "\n",
    "for singer in singerlist:\n",
    "    Singers = URIRef(SN[singer])\n",
    "    g.add((Singers, RDF.type, SN.Singer))\n",
    "    checklt =[]\n",
    "    for index, row in instagram.iterrows():\n",
    "        name = ''\n",
    "        for n in row['Owner'].split(' '):\n",
    "            name = name +n\n",
    "        checklt.append(name)\n",
    "        if name == singer:\n",
    "            g.add((Singers, SN['username'], Literal(row['Username'], datatype=XSD.string)))\n",
    "            for c in str(row['Country']).split(','):\n",
    "                cName = c.strip()\n",
    "                if((countries.index == cName).any() == True):\n",
    "                    code = str(countries[countries.index == cName]['Alpha-2 code'][0]).lower()\n",
    "                    Country = URIRef(CNS[code])\n",
    "                    g.add((Singers, SN['hasCountry'], Country)) \n",
    "    for index, row in youtube.iterrows():\n",
    "        name = ''\n",
    "        for n in row['username'].split(' '):\n",
    "            name = name +n\n",
    "        if name == singer and name not in checklist:\n",
    "            g.add((Singers, SN['channelname'], Literal(row['Channel_Name'], datatype=XSD.string)))\n",
    "            i=0\n",
    "            for c in str(row['Country']).split(',') :\n",
    "                cName = c.strip()\n",
    "                for i in range(0,len(youtube)):\n",
    "                    if ( cName  == countries['Alpha-2 code'][i]):\n",
    "                        code = str(countries['Alpha-2 code'][i]).lower()\n",
    "                        cty = URIRef(CNS[code])\n",
    "                        g.add((Singers, SN['hasCountry'], cty)) \n",
    "                        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- saving serialization ---\n",
      "CPU times: total: 31.2 ms\n",
      "Wall time: 31.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# print all the data in the Turtle format\n",
    "print(\"--- saving serialization ---\")\n",
    "with open(savePath + 'singer.ttl', 'w', encoding=\"utf-8\") as file:\n",
    "    file.write(g.serialize(format='turtle'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Celebrity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lengeth =  945\n"
     ]
    }
   ],
   "source": [
    "g = Graph()\n",
    "\n",
    "CB = Namespace(\"Celebrity#\")\n",
    "g.bind(\"countries\", CNS)\n",
    "g.bind(\"cb\", CB)\n",
    "celeblist = []\n",
    "\n",
    "\n",
    "for index, row in instagram.iterrows():\n",
    "    namelist = []\n",
    "    for name in row['Owner'].split(' '):\n",
    "        namelist.append(name)\n",
    "    name = ''\n",
    "    for i in range(0,len(namelist)): \n",
    "        name = name + namelist[i]\n",
    "\n",
    "    celeblist.append(name)\n",
    "\n",
    "for index, row in twitter.iterrows():\n",
    "    namelist = []\n",
    "    for name in row['name'].split(' '):\n",
    "        namelist.append(name)\n",
    "    name = ''\n",
    "    for i in range(0,len(namelist)): \n",
    "        name = name + namelist[i]\n",
    "    if name not in celeblist:\n",
    "        celeblist.append(name)\n",
    "        \n",
    "# print(celeblist)\n",
    "# print('lengeth = ',len(celeblist))\n",
    "\n",
    "for celeb in celeblist:\n",
    "    Celebrity = URIRef(CB[celeb])\n",
    "    g.add((Celebrity, RDF.type, CB.Celebrity))\n",
    "    checklist =[]\n",
    "    for index, row in instagram.iterrows():\n",
    "        namelist = []\n",
    "        for name in row['Owner'].split(' '):\n",
    "            namelist.append(name)\n",
    "        name = ''\n",
    "        for i in range(0,len(namelist)): \n",
    "            name = name + namelist[i]\n",
    "        checklist.append(name)\n",
    "        if name == celeb:\n",
    "            g.add((Celebrity, CB['username'], Literal(row['Username'], datatype=XSD.string)))\n",
    "            for c in str(row['Country']).split(','):\n",
    "                cName = c.strip()\n",
    "                if((countries.index == cName).any() == True):\n",
    "                    code = str(countries[countries.index == cName]['Alpha-2 code'][0]).lower()\n",
    "                    Country = URIRef(CNS[code])\n",
    "                    g.add((Celebrity, CB['hasCountry'], Country)) \n",
    "        \n",
    "        \n",
    "    for index, row in twitter.iterrows():\n",
    "        namelist = []\n",
    "        for name in row['name'].split(' '):\n",
    "            namelist.append(name)\n",
    "        name = ''\n",
    "        for i in range(0,len(namelist)): \n",
    "            name = name + namelist[i]\n",
    "        if name == celeb and name not in checklist:\n",
    "            g.add((Celebrity, CB['username'], Literal(row['twitter_username'], datatype=XSD.string))) \n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- saving serialization ---\n",
      "CPU times: total: 93.8 ms\n",
      "Wall time: 101 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# print all the data in the Turtle format\n",
    "print(\"--- saving serialization ---\")\n",
    "with open(savePath + 'celebrity.ttl', 'w', encoding=\"utf-8\") as file:\n",
    "    file.write(g.serialize(format='turtle'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
